PR: https://github.com/odoo/odoo/pull/

From: 1a8c1fd8ce4487e0ea8037e7009965b797c43e8f
From: Thibault Delavallée
Date: 2019-11-25 09:47:36

Breaking data model changes score: 10.4, change matches:
-    title = fields.Char('Title', required=True, translate=True)
-    question = fields.Char('Question', related="title")
-    description = fields.Html('Description', help="Use this field to add additional explanations about your question", translate=True)
-    answer_score = fields.Float('Score for this choice',
+    answer_score = fields.Float('Score for this choice', help="A positive score indicates a correct choice; a negative or null score indicates a wrong answer")
-    description = fields.Html("Description", translate=True,
+    description = fields.Html(
-    state = fields.Selection(
-    category = fields.Selection([
-    is_attempts_limited = fields.Boolean('Limited number of attempts',
+    is_attempts_limited = fields.Boolean('Limited number of attempts', help="Check this option if you want to limit the number of attempts per user")
-    attempt_number = fields.Integer("Attempt n°", compute='_compute_attempt_number')
-    last_displayed_page_id = fields.Many2one('survey.question', string='Last displayed question/page')
-    deadline = fields.Datetime('Deadline', help="Datetime until customer can open the survey and submit answers")

Total Changes: 260

[MOV] survey: reorganize a bit code and files

PURPOSE

Purpose is to perform some cleaning in survey models: naming, ordering,
dead code [0]. As new features are about to land in survey, notably live
interactions [1] and new survey building [2] performing a pre cleaning
is necessary [3].

SPECIFICATIONS

Code move main points

  * move fields to have them grouped by main use;
  * move methods to have them grouped by main purpose;
  * reorganize some line breaks to ease reading files;

Globally this code move is done according to our famous guidelines.

No functional changes should occur with this commit. It contains only
code move, not any change at all.

LINKS

[0] Related to Task ID 2144393 (surveys split / cleaning)
[1] Task ID 1972640 (live interactions)
[2] Task ID 2119587 (new frontend for building surveys)
[3] Task ID 2061901 (survey models cleaning and preparation)

PR #40623

================================= pseudo patch: =================================

--- a/addons/survey/models/survey_question.py
+++ b/addons/survey/models/survey_question.py
@@ -50,7 +50,6 @@ class SurveyQuestion(models.Model):
 
         That makes the use and display of these information at view and controller levels easier to understand.
     """
-
     _name = 'survey.question'
     _description = 'Survey Question'
     _rec_name = 'question'
@@ -63,23 +62,24 @@ class SurveyQuestion(models.Model):
             defaults['question_type'] = False if defaults.get('is_page') == True else 'free_text'
         return defaults
 
-    # Question metadata
+    # question generic data
+    title = fields.Char('Title', required=True, translate=True)
+    question = fields.Char('Question', related="title")
+    description = fields.Html('Description', help="Use this field to add additional explanations about your question", translate=True)
     survey_id = fields.Many2one('survey.survey', string='Survey', ondelete='cascade')
-    page_id = fields.Many2one('survey.question', string='Page', compute="_compute_page_id", store=True)
-    question_ids = fields.One2many('survey.question', string='Questions', compute="_compute_question_ids")
     scoring_type = fields.Selection(related='survey_id.scoring_type', string='Scoring Type', readonly=True)
     sequence = fields.Integer('Sequence', default=10)
-    # Question
+    # page specific
     is_page = fields.Boolean('Is a page?')
+    question_ids = fields.One2many('survey.question', string='Questions', compute="_compute_question_ids")
     questions_selection = fields.Selection(
         related='survey_id.questions_selection', readonly=True,
         help="If randomized is selected, add the number of random questions next to the section.")
     random_questions_count = fields.Integer(
         'Random questions count', default=1,
         help="Used on randomized sections to take X random questions from all the questions of that section.")
-    title = fields.Char('Title', required=True, translate=True)
-    question = fields.Char('Question', related="title")
-    description = fields.Html('Description', help="Use this field to add additional explanations about your question", translate=True)
+    # question specific
+    page_id = fields.Many2one('survey.question', string='Page', compute="_compute_page_id", store=True)
     question_type = fields.Selection([
         ('free_text', 'Multiple Lines Text Box'),
         ('textbox', 'Single Line Text Box'),
@@ -89,18 +89,18 @@ class SurveyQuestion(models.Model):
         ('simple_choice', 'Multiple choice: only one answer'),
         ('multiple_choice', 'Multiple choice: multiple answers allowed'),
         ('matrix', 'Matrix')], string='Question Type')
-    # simple choice / multiple choice / matrix
+    # -- simple choice / multiple choice / matrix
     labels_ids = fields.One2many(
         'survey.label', 'question_id', string='Types of answers', copy=True,
         help='Labels used for proposed choices: simple choice, multiple choice and columns of matrix')
-    # matrix
+    # -- matrix
     matrix_subtype = fields.Selection([
         ('simple', 'One choice per row'),
         ('multiple', 'Multiple choices per row')], string='Matrix Type', default='simple')
     labels_ids_2 = fields.One2many(
         'survey.label', 'question_id_2', string='Rows of the Matrix', copy=True,
         help='Labels used for proposed choices: rows of matrix')
-    # Display options
+    # -- display options
     column_nb = fields.Selection([
         ('12', '1'), ('6', '2'), ('4', '3'), ('3', '4'), ('2', '6')],
         string='Number of columns', default='12',
@@ -108,11 +108,11 @@ class SurveyQuestion(models.Model):
     display_mode = fields.Selection(
         [('columns', 'Radio Buttons'), ('dropdown', 'Selection Box')],
         string='Display Mode', default='columns', help='Display mode of simple choice questions.')
-    # Comments
+    # -- comments
     comments_allowed = fields.Boolean('Show Comments Field')
     comments_message = fields.Char('Comment Message', translate=True, default=lambda self: _("If other, please specify:"))
     comment_count_as_answer = fields.Boolean('Comment Field is an Answer Choice')
-    # Validation
+    # question validation
     validation_required = fields.Boolean('Validate entry')
     validation_email = fields.Boolean('Input must be an email')
     validation_length_min = fields.Integer('Minimum Text Length')
@@ -124,10 +124,9 @@ class SurveyQuestion(models.Model):
     validation_min_datetime = fields.Datetime('Minimum Datetime')
     validation_max_datetime = fields.Datetime('Maximum Datetime')
     validation_error_msg = fields.Char('Validation Error message', translate=True, default=lambda self: _("The answer you entered is not valid."))
-    # Constraints on number of answers (matrices)
     constr_mandatory = fields.Boolean('Mandatory Answer')
     constr_error_msg = fields.Char('Error message', translate=True, default=lambda self: _("This question requires an answer."))
-    # Answer
+    # answers
     user_input_line_ids = fields.One2many(
         'survey.user_input_line', 'question_id', string='Answers',
         domain=[('skipped', '=', False)], groups='survey.group_survey_user')
@@ -151,6 +150,39 @@ class SurveyQuestion(models.Model):
         if self.is_page:
             self.question_type = False
 
+    @api.depends('survey_id.question_and_page_ids.is_page', 'survey_id.question_and_page_ids.sequence')
+    def _compute_question_ids(self):
+        """Will take all questions of the survey for which the index is higher than the index of this page
+        and lower than the index of the next page."""
+        for question in self:
+            if question.is_page:
+                next_page_index = False
+                for page in question.survey_id.page_ids:
+                    if page._index() > question._index():
+                        next_page_index = page._index()
+                        break
+
+                question.question_ids = question.survey_id.question_ids.filtered(lambda q:
+                    q._index() > question._index() and (not next_page_index or q._index() < next_page_index))
+            else:
+                question.question_ids = self.env['survey.question']
+
+    @api.depends('survey_id.question_and_page_ids.is_page', 'survey_id.question_and_page_ids.sequence')
+    def _compute_page_id(self):
+        """Will find the page to which this question belongs to by looking inside the corresponding survey"""
+        for question in self:
+            if question.is_page:
+                question.page_id = None
+            else:
+                question.page_id = next(
+                    (iter(question
+                        .survey_id
+                        .question_and_page_ids
+                        .filtered(lambda q: q.is_page and q.sequence < question.sequence)
+                        .sorted(reverse=True))),
+                    None
+                )
+
     # Validation methods
     def validate_question(self, answer, comment=None):
         """ Validate question, depending on question type and parameters
@@ -249,39 +281,6 @@ class SurveyQuestion(models.Model):
             return {self.id: self.constr_error_msg}
         return {}
 
-    @api.depends('survey_id.question_and_page_ids.is_page', 'survey_id.question_and_page_ids.sequence')
-    def _compute_question_ids(self):
-        """Will take all questions of the survey for which the index is higher than the index of this page
-        and lower than the index of the next page."""
-        for question in self:
-            if question.is_page:
-                next_page_index = False
-                for page in question.survey_id.page_ids:
-                    if page._index() > question._index():
-                        next_page_index = page._index()
-                        break
-
-                question.question_ids = question.survey_id.question_ids.filtered(lambda q:
-                    q._index() > question._index() and (not next_page_index or q._index() < next_page_index))
-            else:
-                question.question_ids = self.env['survey.question']
-
-    @api.depends('survey_id.question_and_page_ids.is_page', 'survey_id.question_and_page_ids.sequence')
-    def _compute_page_id(self):
-        """Will find the page to which this question belongs to by looking inside the corresponding survey"""
-        for question in self:
-            if question.is_page:
-                question.page_id = None
-            else:
-                question.page_id = next(
-                    (iter(question
-                        .survey_id
-                        .question_and_page_ids
-                        .filtered(lambda q: q.is_page and q.sequence < question.sequence)
-                        .sorted(reverse=True))),
-                    None
-                )
-
     def _index(self):
         """We would normally just use the 'sequence' field of questions BUT, if the pages and questions are
         created without ever moving records around, the sequence field can be set to 0 for all the questions.
@@ -295,6 +294,7 @@ class SurveyQuestion(models.Model):
 
         return self.labels_ids.filtered(lambda label: label.is_correct)
 
+
 class SurveyLabel(models.Model):
     """ A suggested answer for a question """
     _name = 'survey.label'
@@ -307,8 +307,7 @@ class SurveyLabel(models.Model):
     sequence = fields.Integer('Label Sequence order', default=10)
     value = fields.Char('Suggested value', translate=True, required=True)
     is_correct = fields.Boolean('Is a correct answer')
-    answer_score = fields.Float('Score for this choice',
-    help="A positive score indicates a correct choice; a negative or null score indicates a wrong answer")
+    answer_score = fields.Float('Score for this choice', help="A positive score indicates a correct choice; a negative or null score indicates a wrong answer")
 
     @api.constrains('question_id', 'question_id_2')
     def _check_question_not_empty(self):

--- a/addons/survey/models/survey_survey.py
+++ b/addons/survey/models/survey_survey.py
@@ -26,23 +26,24 @@ class Survey(models.Model):
 
     # description
     title = fields.Char('Survey Title', required=True, translate=True)
-    description = fields.Html("Description", translate=True,
+    description = fields.Html(
+        "Description", translate=True,
         help="The description will be displayed on the home page of the survey. You can use this to give the purpose and guidelines to your candidates before they start it.")
     color = fields.Integer('Color Index', default=0)
     thank_you_message = fields.Html("Thanks Message", translate=True, help="This message will be displayed when survey is completed")
     active = fields.Boolean("Active", default=True)
+    state = fields.Selection(selection=[
+        ('draft', 'Draft'), ('open', 'In Progress'), ('closed', 'Closed')
+    ], string="Survey Stage", default='draft', required=True,
+        group_expand='_read_group_states')
+    category = fields.Selection([
+        ('default', 'Generic Survey')], string='Category',
+        default='default', required=True,
+        help='Category is used to know in which context the survey is used. Various apps may define their own categories when they use survey like jobs recruitment or employee appraisal surveys.')
+    # questions
     question_and_page_ids = fields.One2many('survey.question', 'survey_id', string='Sections and Questions', copy=True)
     page_ids = fields.One2many('survey.question', string='Pages', compute="_compute_page_and_question_ids")
     question_ids = fields.One2many('survey.question', string='Questions', compute="_compute_page_and_question_ids")
-    state = fields.Selection(
-        string="Survey Stage",
-        selection=[
-                ('draft', 'Draft'),
-                ('open', 'In Progress'),
-                ('closed', 'Closed'),
-        ], default='draft', required=True,
-        group_expand='_read_group_states'
-    )
     questions_layout = fields.Selection([
         ('one_page', 'One page with all the questions'),
         ('page_per_section', 'One page per section'),
@@ -53,12 +54,7 @@ class Survey(models.Model):
         ('random', 'Randomized per section')],
         string="Selection", required=True, default='all',
         help="If randomized is selected, add the number of random questions next to the section.")
-
-    category = fields.Selection([
-        ('default', 'Generic Survey')], string='Category',
-        default='default', required=True,
-        help='Category is used to know in which context the survey is used. Various apps may define their own categories when they use survey like jobs recruitment or employee appraisal surveys.')
-    # content
+    # attendees
     user_input_ids = fields.One2many('survey.user_input', 'survey_id', string='User responses', readonly=True, groups='survey.group_survey_user')
     # security / access
     access_mode = fields.Selection([
@@ -76,15 +72,14 @@ class Survey(models.Model):
     answer_score_avg = fields.Float("Avg Score %", compute="_compute_survey_statistic")
     success_count = fields.Integer("Success", compute="_compute_survey_statistic")
     success_ratio = fields.Integer("Success Ratio", compute="_compute_survey_statistic")
-    # scoring and certification fields
+    # scoring / certification
     scoring_type = fields.Selection([
         ('no_scoring', 'No scoring'),
         ('scoring_with_answers', 'Scoring with answers at the end'),
         ('scoring_without_answers', 'Scoring without answers at the end')],
         string="Scoring", required=True, default='no_scoring')
     passing_score = fields.Float('Passing score (%)', required=True, default=80.0)
-    is_attempts_limited = fields.Boolean('Limited number of attempts',
-        help="Check this option if you want to limit the number of attempts per user")
+    is_attempts_limited = fields.Boolean('Limited number of attempts', help="Check this option if you want to limit the number of attempts per user")
     attempts_limit = fields.Integer('Number of attempts', default=1)
     is_time_limited = fields.Boolean('The survey is limited in time')
     time_limit = fields.Float("Time limit (minutes)")
@@ -93,7 +88,6 @@ class Survey(models.Model):
         'mail.template', 'Email Template',
         domain="[('model', '=', 'survey.user_input')]",
         help="Automated email sent to the user when he succeeds the certification, containing his certification document.")
-
     # Certification badge
     #   certification_badge_id_dummy is used to have two different behaviours in the form view :
     #   - If the certification badge is not set, show certification_badge_id and only display create option in the m2o
@@ -218,7 +212,7 @@ class Survey(models.Model):
         return super(Survey, self).copy_data(default)
 
     # ------------------------------------------------------------
-    # TECHNICAL
+    # ANSWER MANAGEMENT
     # ------------------------------------------------------------
 
     def _create_answer(self, user=False, partner=False, email=False, test_entry=False, check_attempts=True, **additional_vals):
@@ -346,8 +340,9 @@ class Survey(models.Model):
         return self.attempts_limit - self.env['survey.user_input'].search_count(domain)
 
     # ------------------------------------------------------------
-    # ACTIONS
+    # QUESTIONS MANAGEMENT
     # ------------------------------------------------------------
+
     @api.model
     def _get_pages_or_questions(self, user_input):
         if self.questions_layout == 'one_page':
@@ -375,7 +370,6 @@ class Survey(models.Model):
 
         return previous_page_id
 
-
     @api.model
     def next_page_or_question(self, user_input, page_or_question_id):
         """ The next page to display to the user, knowing that page_id is the id
@@ -433,6 +427,10 @@ class Survey(models.Model):
             questions = questions & answer.question_ids
         return questions, page_or_question_id
 
+    # ------------------------------------------------------------
+    # ACTIONS
+    # ------------------------------------------------------------
+
     def action_draft(self):
         self.write({'state': 'draft'})
 

--- a/addons/survey/models/survey_user.py
+++ b/addons/survey/models/survey_user.py
@@ -25,18 +25,15 @@ def dict_keys_startswith(dictionary, string):
 
 class SurveyUserInput(models.Model):
     """ Metadata for a set of one user's answers to a particular survey """
-
     _name = "survey.user_input"
     _rec_name = 'survey_id'
     _description = 'Survey User Input'
 
-    # description
+    # answer description
     survey_id = fields.Many2one('survey.survey', string='Survey', required=True, readonly=True, ondelete='cascade')
     scoring_type = fields.Selection(string="Scoring", related="survey_id.scoring_type")
-    is_attempts_limited = fields.Boolean("Limited number of attempts", related='survey_id.is_attempts_limited')
-    attempts_limit = fields.Integer("Number of attempts", related='survey_id.attempts_limit')
     start_datetime = fields.Datetime('Start date and time', readonly=True)
-    is_time_limit_reached = fields.Boolean("Is time limit reached?", compute='_compute_is_time_limit_reached')
+    deadline = fields.Datetime('Deadline', help="Datetime until customer can open the survey and submit answers")
     input_type = fields.Selection([
         ('manually', 'Manual'), ('link', 'Invitation')],
         string='Answer Type', default='manually', required=True, readonly=True)
@@ -45,24 +42,26 @@ class SurveyUserInput(models.Model):
         ('skip', 'Partially completed'),
         ('done', 'Completed')], string='Status', default='new', readonly=True)
     test_entry = fields.Boolean(readonly=True)
-    # identification and access
+    last_displayed_page_id = fields.Many2one('survey.question', string='Last displayed question/page')
+    # attempts management
+    is_attempts_limited = fields.Boolean("Limited number of attempts", related='survey_id.is_attempts_limited')
+    attempts_limit = fields.Integer("Number of attempts", related='survey_id.attempts_limit')
+    attempt_number = fields.Integer("Attempt n°", compute='_compute_attempt_number')
+    is_time_limit_reached = fields.Boolean("Is time limit reached?", compute='_compute_is_time_limit_reached')
+    # identification / access
     token = fields.Char('Identification token', default=lambda self: str(uuid.uuid4()), readonly=True, required=True, copy=False)
-    # no unique constraint, as it identifies a pool of attempts
-    invite_token = fields.Char('Invite token', readonly=True, copy=False)
+    invite_token = fields.Char('Invite token', readonly=True, copy=False)  # no unique constraint, as it identifies a pool of attempts
     partner_id = fields.Many2one('res.partner', string='Partner', readonly=True)
     email = fields.Char('E-mail', readonly=True)
-    attempt_number = fields.Integer("Attempt n°", compute='_compute_attempt_number')
-
-    # Displaying data
-    last_displayed_page_id = fields.Many2one('survey.question', string='Last displayed question/page')
-    # answers
+    # questions / answers
     user_input_line_ids = fields.One2many('survey.user_input_line', 'user_input_id', string='Answers', copy=True)
-    # Pre-defined questions
     question_ids = fields.Many2many('survey.question', string='Predefined Questions', readonly=True)
-    deadline = fields.Datetime('Deadline', help="Datetime until customer can open the survey and submit answers")
-    # Stored for performance reasons while displaying results page
-    quizz_score = fields.Float("Score (%)", compute="_compute_quizz_score", store=True, compute_sudo=True)
-    quizz_passed = fields.Boolean('Quizz Passed', compute='_compute_quizz_passed', store=True, compute_sudo=True)
+    quizz_score = fields.Float("Score (%)", compute="_compute_quizz_score", store=True, compute_sudo=True)  # stored for perf reasons
+    quizz_passed = fields.Boolean('Quizz Passed', compute='_compute_quizz_passed', store=True, compute_sudo=True)  # stored for perf reasons
+
+    _sql_constraints = [
+        ('unique_token', 'UNIQUE (token)', 'A token must be unique!'),
+    ]
 
     @api.depends('user_input_line_ids.answer_score', 'user_input_line_ids.question_id')
     def _compute_quizz_score(self):
@@ -83,49 +82,6 @@ class SurveyUserInput(models.Model):
         for user_input in self:
             user_input.quizz_passed = user_input.quizz_score >= user_input.survey_id.passing_score
 
-    _sql_constraints = [
-        ('unique_token', 'UNIQUE (token)', 'A token must be unique!'),
-    ]
-
-    @api.model
-    def do_clean_emptys(self):
-        """ Remove empty user inputs that have been created manually
-            (used as a cronjob declared in data/survey_cron.xml)
-        """
-        an_hour_ago = fields.Datetime.to_string(datetime.datetime.now() - datetime.timedelta(hours=1))
-        self.search([('input_type', '=', 'manually'),
-                     ('state', '=', 'new'),
-                     ('create_date', '<', an_hour_ago)]).unlink()
-
-    @api.model
-    def _generate_invite_token(self):
-        return str(uuid.uuid4())
-
-    def action_resend(self):
-        partners = self.env['res.partner']
-        emails = []
-        for user_answer in self:
-            if user_answer.partner_id:
-                partners |= user_answer.partner_id
-            elif user_answer.email:
-                emails.append(user_answer.email)
-
-        return self.survey_id.with_context(
-            default_existing_mode='resend',
-            default_partner_ids=partners.ids,
-            default_emails=','.join(emails)
-        ).action_send_survey()
-
-    def action_print_answers(self):
-        """ Open the website page with the survey form """
-        self.ensure_one()
-        return {
-            'type': 'ir.actions.act_url',
-            'name': "View Answers",
-            'target': 'self',
-            'url': '/survey/print/%s?answer_token=%s' % (self.survey_id.access_token, self.token)
-        }
-
     @api.depends('start_datetime', 'survey_id.is_time_limited', 'survey_id.time_limit')
     def _compute_is_time_limit_reached(self):
         """ Checks that the user_input is not exceeding the survey's time limit. """
@@ -167,6 +123,45 @@ class SurveyUserInput(models.Model):
 
                 user_input.attempt_number = attempt_number
 
+    @api.model
+    def do_clean_emptys(self):
+        """ Remove empty user inputs that have been created manually
+            (used as a cronjob declared in data/survey_cron.xml)
+        """
+        an_hour_ago = fields.Datetime.to_string(datetime.datetime.now() - datetime.timedelta(hours=1))
+        self.search([('input_type', '=', 'manually'),
+                     ('state', '=', 'new'),
+                     ('create_date', '<', an_hour_ago)]).unlink()
+
+    def action_resend(self):
+        partners = self.env['res.partner']
+        emails = []
+        for user_answer in self:
+            if user_answer.partner_id:
+                partners |= user_answer.partner_id
+            elif user_answer.email:
+                emails.append(user_answer.email)
+
+        return self.survey_id.with_context(
+            default_existing_mode='resend',
+            default_partner_ids=partners.ids,
+            default_emails=','.join(emails)
+        ).action_send_survey()
+
+    def action_print_answers(self):
+        """ Open the website page with the survey form """
+        self.ensure_one()
+        return {
+            'type': 'ir.actions.act_url',
+            'name': "View Answers",
+            'target': 'self',
+            'url': '/survey/print/%s?answer_token=%s' % (self.survey_id.access_token, self.token)
+        }
+
+    @api.model
+    def _generate_invite_token(self):
+        return str(uuid.uuid4())
+
     def _mark_done(self):
         """ This method will:
         1. mark the state as 'done'
